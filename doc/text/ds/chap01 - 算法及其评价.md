# 算法及其评价

本章是《数据结构》的第一章。这一章将从算法的定义和评价出发，重点介绍在《数据结构》学科中最为重要的思维方法：**递归**（recursion）。这一思维方法的建立为《数据结构》后续知识点的理解和掌握打下了基础。

## 算法的定义和评价

> 我们想事情，做工作，想得对不对，做得好不好，要有一个根本的衡量尺度，这就是人民拥护不拥护，人民赞成不赞成，人民高兴不高兴，人民答应不答应。
>
> ——Chairman Jiang

### 概念和定义的争议

**算法** （algorithm）是计算机领域的核心概念之一。和更加核心的概念“**计算机** （computer）”一样，它没有一个被广泛承认的规范定义。一些教材会把算盘甚至算筹划归“计算机”的范畴，并把手工算法（如尺规作图，甚至按照菜谱烹饪食物）划归“算法”的范畴；而另一些教材仅仅承认现代电子计算机为“计算机”，并把“算法”限定可以在图灵机上通过有限步骤执行的计算方法。

这种**概念和定义的争议**在计算机领域广泛存在，它主要来自以下几个原因（下文中提到的概念，将在后续章节中展开介绍）。

1. <u>为了叙述简便，有些概念会借用一个已经存在的专有名词，从而引发歧义</u>。如“**树** （tree）”这个词在计算机领域就有常用但迥然不同的两个概念。图论中的“树”出现得比较早，但没有人愿意将工程界经常出现的“树”称为“有限有根有序有标号的树”——英文里这些词并不能缩写为“四有树”。
2. <u>不同科学家互相不服气，都认为自己提出的定义更有优越性，从而引发歧义</u>。这个现象的典型例子是“计数时从0开始还是从1开始”。从0开始是有一定数学上的优越性的，可以避免一些公式出现刻意的“+1”余项；但从1开始计数更符合自然习惯。这个问题直接导致在有些问题（如“树的高度”）上，国内不同高校的教材采用的说法互不相同，从而引起一些学生在准备考研时感到困惑。
3. <u>随着计算机领域的快速发展，一些概念的含义会发生变化</u>。如众所周知，“**字节** （byte）”表示8个二进制位；但在远古时代，不同计算机采用的“字节”定义互不相同，有些计算机甚至是十进制的，那个时候一个字节可能表示2个十进制位。
4. <u>受计算机科学家的意识形态影响，同一概念的用词有所不同</u>。如“树上的前驱和后继节点”这一概念，现在普遍使用的词是parent和child；然而思想老旧的人可能还在用father和son，进步主义者则可能会用mother和daughter。
5. <u>计算机领域的大多数成果出自美国，而英语翻译为汉语时，不同译者可能采用不同的译法</u>。如robustness有音译的“**鲁棒性** ”和意译的“**稳健性** ”，hash有音译的“**哈希** ”和意译的“**散列** ”。
6. <u>计算机相关企业为了销售产品或取得投资，存在滥用、炒作部分计算机概念的情况</u>。如“人工智能”“大数据”“云计算”“区块链”等概念是这个现象的重灾区。不过，这些问题概念和考研复习关系不大。

由于以上这种种原因，计算机领域的很多概念都不存在“标准”、“权威”的定义，而是存在争议的。<u>清华大学的考试在争议问题上都会特别标注</u>（如“注：空树的高度认为是-1。”）。其他学校不一定会这样做，因此请务必购买您的目标高校使用的教材；如果教材和您使用的考研辅导书冲突，则需要特别注意。

### 算法定义的四个要素

回到算法的问题上来。在本笔记中，笔者采用“限定词+中心语”的方式定义“**算法** （algorithm）”，而不采用较难理解的数学定义。该定义出自*The Art of Computer Programming Vol 1, 3^rd^ Edition* （Donald E. Knuth，1997）。

> **算法** （algorithm）是<u>对于给定的输入，通过有限的、可行的步骤可以得到确定的、满足预期条件的输出结果的计算方法</u>。

这一定义规定了算法的4个要素：**有限性、可行性、确定性、有输出** 。

值得一提的是，“有输入”这个要素在这个定义中是**可选的**（optional）。这一定义认为形如“找到所有int范围内的素数”就是没有输入的算法。但相对地，“有输出”则是**必需的**，否则算法就失去了存在的意义。

根据上述定义，下面这些都不能成为算法：

1. 计算圆周率的十进制小数形式。（无法在有限步骤内完成）
2. 如果哥德巴赫猜想正确，输出1，否则输出0。（在当前阶段，*不满足可行性*）
3. 输入两个整数a和b，输出a除以b的余数。（*不满足确定性*，因为在b为0的情况下除法没有定义）
4. 读取一个文件。（*没有输出*）

### 在算法设计题中使用定义

*试卷上并不会让您判断一个计算方法是否为算法，因此背诵定义看上去并没有什么用*。这一定义是帮助您完成其他类型的题目的。

在《数据结构》考试中，关于算法最多的是**评价题**，通常有且只有一道的是**设计题**；您在复试的机试中还会面对若干道算法**上机设计题**。理解上述定义，有助于让您在设计算法后“四省吾身”：

1. <u>是否必定能结束</u>？如果您使用了`while (true)`或者`for(;;)`这样的无限循环，或使用了`goto`强制跳转，则存在不满足有限性的潜在风险。
2. <u>是否有语法错误</u>？在初试中，算法设计题的答案通常以伪代码或代码给出。语法错误不一定会被扣分，但**语义歧义**一定会被扣分。
3. <u>是否被正确定义</u>？除以0、空指针、下标越界等问题，都可能是被意外扣分的导火索。在机试中，甚至可能被有针对地设计的测试数据“重点打击”，使您失去大半甚至全部分数。
4. <u>是否有输出结果</u>？对于常见的数据结构维护类题目，数据结构本身就是输出结果，不需要再额外做输出。另一些题目则可能需要输出；尤其在机试时，您可能会忘记某个特殊分支的输出。

### 算法的评价维度

作为一种解决问题的方法，算法的评价是多尺度的，它们构成了算法题的另一种题型。即使是在算法设计题中，也经常有“对设计的算法进行评价”的附加要求。

1. **正确性**。**正确性检验**通常分为两个方面：**有限性检验**和**结果正确性检验** 。

   1. **有限性检验** 。即判定带有无限循环或强制跳转的算法是否必定能终止。没有无限循环或强制跳转的情况，有限性是默认的。
   
   2. **结果正确性检验** 。即验证输出的结果满足算法的需求。在算法有确定的正确结果时，这一检验是“非黑即白”的；而在算法没有确定的正确结果时，可能需要专用的检验程序甚至人工打分（比如较早的象棋AI，往往是以高手对一些局面的形势打分作为基础训练数据的）。
   
      *作为四要素中的另外两项：**可行性**是否成立往往一眼便知；而**确定性**如果不是一眼便知，则往能蕴含在其他两项检验当中。证明可以<u>通过有限步得到正确结果</u>，实际上也就证明了<u>在此期间不存在未定义行为</u>。*
   
2. **效率** 。评价算法效率的标准可以简单概括为“<u>多、快、好、省</u>”。在《数据结构》学科中通常只研究“快”和“省”这2个方面，到《网络原理》部分再展开来讨论全部的4个方面。

   1. **时间效率（快）** 。在计算机上运行算法一定会消耗时间，时间效率高的算法消耗的时间比较短。

   2. **空间效率（省）** 。在计算机上运行算法一定会消耗空间（硬件资源），空间效率高的算法消耗的硬件资源比较少。

      然而，在不同的计算机、不同的操作系统、不同的编程语言实现下，同一算法消耗的时间和空间可能大相径庭。为了抵消这些变量对算法效率评价的干扰作用，在《数据结构》这门学科里进行算法评价时，往往不那么注重真实的时间、空间消耗，而倾向于做**复杂度分析** 。关于复杂度的讨论参见后文。

3. **稳健性** （robustness，又译健壮性、鲁棒性；在看到英文之前，笔者曾一度认为“鲁棒性”这个词来源于山东大汉身体棒的地域刻板印象……）。即算法面对意料之外的输入的能力。
4. **可重用性** 。即算法是否能很方便地用于设计目的之外的其他场合。

在上述4个评价尺度中，<u>正确性和效率是《数据结构》学科研究的主要内容，算法评价题也总是围绕正确性检验和复杂度分析命题</u>；这两个问题留到下一节展开讨论。而稳健性和可重用性，则在课程设置上属于《软件工程》讨论的内容；作为考研复习笔记不再详述。

### 算法的具体实现形式：程序

由于后两个问题更偏向工程而非理论，这两个评价尺度更多地是和**算法的具体实现形式**而不是**算法本身**高度相关。*初学者很容易将算法和算法的具体实现形式混淆*。

算法的具体实现形式是依赖于具体的计算机、操作系统、编程语言的具体的**程序** （program）。对程序的分析和对算法的分析有着基础上的差异，下面的例子中可以看出这一点。

```c++
// 问题1.1 - 从1加到n
// 输入：正整数n
// 输出：1 + 2 + ... + n的和
```

Gauss小时候就得到了这个问题的一般公式，您很容易得到下面的算法。

```c++
// 算法1.1
// 1. 输入正整数n
// 2. 计算A = n*(n+1)/2
// 3. 输出结果A
```

根据这一算法，您可以编写出下面的程序：

```c++
// 算法1.1A
int f1(int n) {
    return n*(n+1)/2;
}
```

由于这个**算法**的正确性十分显然，以至于您或许觉得这个**程序**也毫无问题。直到您看到了另一个程序：

```c++
// 算法1.1B
int f2(int n) {
    return n % 2 == 1 ? (n+1)/2*n : n/2*(n+1);
}
```

您大概立刻意识到了**算法1.1A**存在的问题：对于某一区间内的`n`，`n*(n+1)/2`的和不会超过`max_int`的值，但`n*(n+1)`会超过这个值。比如，当`n`取`50000`的时候，**算法1.1B**能够输出正确的结果，而**算法1.1A**则会因为数据溢出而输出一个负数。您可以很容易算出这个“**算法1.1B**结果正确而**算法1.1A**不正确”的区间。

但**算法1.1B**也很难称之为无可挑剔。因为如果`n`更大一些，比如取`100000`，它也无法输出一个正确的值。

所以是**算法1.1**不正确吗？显然不是，Gauss已经证明了它的正确性。**算法1.1A**和**算法1.1B**不能对所有输入的`int`型数据得到正确的结果，这是因为`int`有数据范围限制。但是，世界上并不存在无数据范围限制的计算机（因为一台计算机上的硬件资源必定是有限的），所以如果溢出算是一种“错误”，就不会存在“正确”的算法了。

那么，是否有必要为输入的数据`n`增加一个范围限制，来保证**算法1.1**的正确？事实上这个范围限制很难设计。

其原因在于，<u>算法必须是独立于计算机的</u>。现在`max_int`当然是`2147483647`，但是在古代的16位计算机上，这个值有可能是`65536`（ANSI C标准只规定了`int`至少16位）。此外，在C++里整型数据有显式的上界`max_int`，但在另一些支持`BigInteger`的语言（如Java）中，整数是没有显式的上界的，其实际上界和计算机的空闲存储空间相关，这在每一台计算机上几乎都是不一样的。

如果一定要评价**算法1.1**的不足，只能说它在**稳健性**上有所欠缺：<u>现代计算机处理溢出数据是截断的</u>，所以当`n*(n+1)/2`的超出`int`范围时，它可能会输出一个负数。

为了提高稳健性，更好的算法可能会让`n*(n+1)/2`的和超出`int`范围时输出`max_int`，以表示“这个结果很大”。事实上，有些古代计算机在设计时就让“超出`int`范围时，整形成`max_int`”；但这样设计硬件或指令集是得不偿失的，在《组成原理》中您会看到这一点。

在《数据结构》这门学科中，您可以认为**算法1.1**是一个毫无疑问的好算法。它已有Gauss证明是正确的，并且在时间和空间上都效率很高。

## 正确性检验

> 伟大、光荣、正确的中国共产党万岁！
> 伟大、光荣、英雄的中国人民万岁！
>
> ——Chairman Xi

在上一节已经说明，**正确性检验**可以拆解为两个方面：**有限性检验**和**结果正确性检验**。试卷中会出现的题目，输出结果往往有唯一正确的“标准答案”，所以这两项检验往往可以一并完成，即检验算法是否能<u>在有限时间内输出正确结果</u>。

解决正确性检验的一般方法是**递降法**。它的思想基础是在计算机领域至关重要、并且是《数据结构》学科核心的**递归思维方法**；它的理论依据则是作为在整数公理系统中举足轻重的**数学归纳法**。

在本节中，将从数学归纳法的角度出发介绍递降法的原理，这部分有助于让您对递归思维有更加深刻的理解。当然在实际考试中只要会用递降法解题即可，您也可以跳过数学的部分。

### 经典归纳和经典递降

在高中理科数学中介绍了数学归纳法的经典形式。由于各省教材不同，您可能接触到过两种表述不太一样的数学归纳法：
$$
\mathbf{定理（第一归纳法）}\\
\begin{align}
&令P(n)是一个关于正整数n的命题。要证明P(n)对一切正整数n为真，只需要证明：\\
&1. P(1)为真。\\
&2. 对一切k\ge1，如果P(k)为真，那么P(k+1)也为真。
\end{align}
$$

$$
\mathbf{定理（第二归纳法）}\\
\begin{align}
&令P(n)是一个关于正整数n的命题。要证明P(n)对一切正整数n为真，只需要证明：\\
&1. P(1)为真。\\
&2. 如果对k<n，P(k)都为真，那么P(n)也为真。
\end{align}
$$

其中，第一归纳法是Piano公理体系的一部分，您可以很轻松地用第一归纳法推导出第二归纳法。另一方面，第二归纳法的**归纳假设**——$\forall k < n,P(k) \mathrm{\space is\space true}$，显然比第一归纳法更强；所以在实际应用数学归纳法进行证明时，通常都使用第二归纳法，而不使用第一归纳法。

> 在上面的表述中，归纳的过程是从1开始的，这比较符合数学研究者的工作习惯。
>
> 在计算机领域，归纳法常常从0开始（有时甚至从-1开始）。显然，这并不影响它的正确性。本节后续对“正整数”相关问题的讨论，一般替换成“自然数”也同样可用。

下文将第二归纳法称为**经典归纳法**。经典归纳法可以用来处理<u>有关正整数的命题</u>。相应地，对于<u>输入是正整数的算法</u>，可以使用与经典归纳法相对应的**经典递降法**。
$$
\mathbf{定理（经典递降法）}\\
\begin{align}
&设算法A(n)的输入数据n为正整数。要证明A(n)对一切正整数n都可以在有限时间内输出正确结果，只需要证明：\\
&1.	A(1)可以在有限时间内输出正确结果。\\
&2.	对于每个n > 1，A(n)可以在有限时间内将问题化归为A(k)，其中k < n。且在A(k)结果正确时，得到的A(n)也正确。
\end{align}
$$

> 经典递降法的正确性由经典归纳法保证。

显然，经典递降法的应用范围非常狭小：只能用来处理输入是正整数的算法。对于实际的算法，它的输入数据通常是多个数、乃至于数组和各种数据结构，而非孤零零的一个正整数。因此，需要对经典归纳法进行推广，从而使其可以应用到更广的范围中，并使其相对应的递降法能够处理更加多样的输入数据。

### 带映射的归纳和递降

在《线性代数》的第一章“行列式”中，您一定见过下面这个经典的命题：
$$
\mathbf{定理（Vendermonde行列式）}\\
D_n=\left|\begin{matrix}
1&1&\cdots&1\\
x_1&x_2&\cdots&x_n\\
\vdots&\vdots&&\vdots\\
x_1^{n-1}&x_2^{n-2}&\cdots &x_{n}^{n-1}
\end{matrix}\right|
=\prod_{1\le j<i\le n}(x_i-x_j)
$$
通常这个命题都是用数学归纳法证明的，您不会有任何违和感。

但在这个命题中，$n$并不是唯一的变量。在$n$之外，还有$x_1,x_2,\cdots,x_n$这$n$个变量。换句话说，这个命题所接受的是一个<u>任意有限长的向量</u>$(x_1,x_2,\cdots,x_n)$。在使用数学归纳法进行证明时，实际上指定了一个映射$f(x_1,x_2,\cdots,x_n)=n$，<u>输入数据是这个映射的原象，而在这个映射的象上做数学归纳法</u>。有些数学书为了指明这一点，会在证明的开头写上“对行列式的阶数$n$做归纳”；而有些书则图省事略去了这句话。

在这个例子中，通过“对行列式的阶数做归纳”，<u>将复杂的输入数据映射到了正整数集</u>，这是一种典型的应用归纳法的技术。类似地，<u>在证明对整数的命题时，可以对它的绝对值做归纳</u>，等等。

一般而言，可以将经典归纳法改写成下面的“带映射的”形式：
$$
\mathbf{定理（带映射的经典归纳法）}\\
\begin{align}
&令P(x)是一个关于x\in X的命题；映射f:X\to N^+是满射。\\
&要证明P(x)对一切x\in X为真，只需要证明：\\
&1. 当f(x_0) =1时，P(x_0)为真。\\
&2. 如果对f(y)<f(x)，P(y)都为真，那么P(x)也为真。
\end{align}
$$

> 可以对命题$Q(n)=P(\mathrm{全部的}f^{-1}(n))$使用经典归纳法，从而证明带映射的经典归纳法成立。

相应地，存在带映射的经典递降法。
$$
\mathbf{定理（带映射的经典递降法）}\\
\begin{align}
&设算法A(x)的输入数据x\in X；映射f:X\to N^+是满射。\\
&要证明A(x)对一切x\in X都可以在有限时间内输出正确结果，只需要证明：\\
&1.	当f(x_0) =1时，A(x_0)可以在有限时间内输出正确结果。\\
&2.	对于每个f(x) > 1，A(x)可以在有限时间内将问题化归为A(y)，其中f(y) < f(x)。\\
&且在A(y)结果正确时，得到的A(x)也正确。
\end{align}
$$
为了让上述定义的$Q(n)$总是存在，$f$需要保证是满射。这又是一项对递降法应用范围的限制，需要想办法清除掉它，得到更加一般的、更加通用的解题方法。

### 良序关系

在带映射的归纳法中，需要通过满射将定义域$X$映射到正整数集$N^+$上。很多时候，这样的满射并不容易构造。与其试图用高超的技巧去构造满射，不如从正整数集$N^+$入手：放宽映射的象的条件，不要求它一定是$N^+$，只需要满足一些和$N^+$相似的性质即可。

对于一般的集合，引入**良序**（well-ordering）的概念：
$$
\mathbf{定义（良序关系）}\\
\begin{align}
&如果集合S上的一个关系≺满足：\\
&	1.（\mathbf{传递性}）如果x≺y且y≺z，那么x≺z。\\
&	2.（\mathbf{归中性}）如果x≺y、y≺x均不成立，那么x=y。\\
&	3.（\mathbf{最小值}）对于集合S的任意非空子集A，存在最小值min⁡A=x。（即对于A中的其他元素y，总有x≺y）\\
&那么称≺是S上的一个\mathbf{良序关系}，同时称S为\mathbf{良序集}。
\end{align}
$$
根据上述定义，熟知的小于关系“<”在正整数集$N^+$上是良序的，而在整数集$Z$上不是良序的。当然，可以通过定义“绝对值小于”让整数集$Z$成为良序集。同时，熟知的小于关系“<”在非负实数集$R^+\cup\{0\}$上不是良序的，因为它不满足最小值条件。

和熟知的正整数集$N^+$相比，一般的良序集具有下面的相似性质：
$$
\mathbf{定理（无穷递降）}\\
在良序集S中，不存在无穷序列\{x_n\}，使x_{j+1} ≺ x_{j}对一切j成立。
$$
这一性质使得在一般的良序集上做归纳法成为可能，后面的小节会回到这个问题上来。

### 字典序

在上一小节，您发现熟知的小于关系在非负实数集$R^+\cup \{0\}$上并不是良序的。如果您感到不服气，想要尝试去构造$R$上的良序关系，几乎一定会无功而返（目前还没有数学家定义出实数集$R$上的显式良序关系）。然而：

> **良序定理**：（ZFC）任何集合都存在良序关系。

在集合论的**ZFC公理体系**下，上述定理成立。在**ZF公理体系**下，该定理和**选择公理**（AC）等价。选择公理是有些反直观的（有兴趣的话可以自行搜索），与它等价的良序定理同样反直观，基本上只能用于理论推导，很难实际应用。

幸运的是，在计算机领域的日常研究中，并不需要使用无所不能的良序定理来“造”出一个良序关系。计算机领域中，输入数据所属的集合总是**可数的**（countable），而<u>可数集合总是可以很轻松地定义良序关系</u>。其中一个典型的例子是所谓的**字典序**（lexicographical order）。

> 实际上，计算机领域的输入数据所属集合总是**有限的**，因为任何硬件设备都存在可承载的数据量上限。但是，在不能用**枚举法**的情况下，通常都会选择将输入集合从有限集扩大为可数集，从而使用针对可数集的**递降法**。

$$
\mathbf{定理（字典序）}\\
\begin{align}
&设{S_n}是一个良序集序列，≺_j是集合Sj上的一个良序关系。\\
&则对于无限笛卡尔积∏S_j=S_1×S_2×S_3×⋯中的两个元素a=(a_1,a_2,a_3,…)和b=(b_1,b_2,b_3,…)，\\
&定义a≺b当且仅当存在某个k，使得a_j=b_j对于1≤j<k恒成立，但a_k ≺_k b_k。\\
&那么≺是∏S_j上的一个良序关系。
\end{align}
$$

上面定义的良序关系，是针对无限长向量的。将它稍微修改一下，就可以用来定义任意长向量。

> 在每个集合$S_j$中增加一个元素$\empty_j$，让这个元素作为$S_j\cup \{\empty_j\}$的最小值。
>
> 对于非无限长的向量$(a_1,a_2,\dots,a_n)$，将其延伸为$(a_1,a_2\dots,a_n,\empty_{n+1},\empty_{n+2},\dots)$，就得到了无限长向量。这个映射是一一对应的，从而可以用无限长向量的字典序去定义任意长向量的字典序。

特别地，由$S_j=\{a,b,\dots,z\}$构成的任意长向量的<u>字典序，就是英文字典中排列单词的顺序</u>。

### 超限的归纳和递降

在定义良序关系之后，就可以使用**超限归纳法**来证明命题。超限归纳法本质上是经典数学归纳法在集合论上的一般形式，可由良序关系的定义直接导出，而无需用到良序定理。
$$
\mathbf{
定理（超限归纳法）}\\
\begin{align}
&令P(x)是一个关于x\in X的命题；f将X映射到关于≺的良序集S。\\
&要证明P(x)对一切x\in X为真，只需要证明：\\
&1. 当f(x_0) =\min S时，P(x_0)为真。\\
&2. 如果对f(y)≺f(x)，P(y)都为真，那么P(x)也为真。
\end{align}
$$

> 上面的表述和经典的超限归纳法表述有所不同。它融合了之前介绍过的“映射”策略。

当$S$取为正整数集$N^+$，良序关系取为熟知的“小于”时，超限归纳法的特例就是经典归纳法。这是最自然的良序关系和良序集。在考研解题过程中，通常都只需要用到这个集合，下面称其为**通常良序集**。

> 尽管解题的时候，通常只会用到通常良序集，但“良序”的思维，仍然广泛存在于计算机领域的各个学科中。

和超限归纳法对应，可以得到一般形式的递降法。
$$
\mathbf{定理（递降法）}\\
\begin{align}
&设算法A(x)的输入数据x\in X；f将X映射到关于≺的良序集S。\\
&要证明A(x)对一切x\in X都可以在有限时间内输出正确结果，只需要证明：\\
&1.	当f(x_0) =\min S时，A(x_0)可以在有限时间内输出正确结果。\\
&2.	对于每个f(x) \ne \min S，A(x)可以在有限时间内将问题化归为有限个A(y_i)，其中f(y_i) ≺f(x)。\\
&且在A(y_i)结果都正确时，得到的A(x)也正确。
\end{align}
$$
递降法和**递归**（recursion）是密不可分的。在递降法中，条件（1）对应了**递归边界**，条件（2）则对应了**递归调用**。边界情况通常对应的是最简单的情况，而递归调用则用来将复杂问题拆解成简单问题。只要您有一定的递归编程的经验，那么递降法是非常容易理解的。

> 递降用于分析算法，而递归用于设计算法，二者思路上相似，只是功能上不同。
>
> 由于<u>递降法用到的计算机思维事实上是递归</u>，下文将不再区分“递降法”和“递归法”。递归（递降）法是《数据结构》学科最为核心的思维方法，在这一章只是用简单的例子介绍它，后面的章节中还会反复出现，并不断增加问题的难度和思维的深度。

下面用几个实际的例子，来说明递降法在正确性检验中的作用。

### 递归算法的正确性检验

```c++
// 问题1.2 - 求最大公因数
// 输入：正整数a、b
// 输出：a和b的最大公因数
```

关于这个问题，如果您有一定编程基础，肯定能一眼就知道如何解决。

> 如果您没有编程基础，暂时也不需要记忆这个算法。相关内容的展开介绍放在了《算法设计》学科中。

```c++
// 算法1.2A
int gcd(int a, int b) {
    if (b == 0) {
        return a;
    } else {
        return gcd(b, a % b);
    }
}
```

上面的**算法1.2A**是著名的最大公因数算法：**Euclid辗转相除法**的<u>递归形式</u>。在这个算法中，递归边界是$(a, 0)$，因此可以定义$f(a, b) = \min(a, b)$，将输入数据映射到通常良序集。接着就可以用递降法处理这个问题了。

1. 如果`a<b`，那么通过1次递归，可变换为等价的`gcd(b, a)`。

2. 如果`a>=b>0`，那么由于`b > a%b`对一切正整数`a,b`成立，所以通过1次递归，可变换为`f(.)`更小的`(b, a%b)`。接下来只要证`gcd(a, b) = gcd(b, a%b)`。您可以自己完成这一证明。下面提供了一种比较简单的证法。

   > **证明** 设`a = kb + l`，其中`l = a % b`。
   >
   > 那么，对于`a`和`b`的公因数`d`，设`a = Ad`，`b = Bd`，则`l = (A-kB)d`。因此`d`也是`b`和`l`的公因数。反之，对于`b`和`l`的公因数`d’`，也可推出`d’`也是`a`和`b`的公因数。
   >
   > 因此`a`和`b`的公因数集合，与`b`和`l`的公因数集合相同；它们的最大值显然也相同。

3. 如果`b=0`，到达边界，`gcd(a, 0) = a`正确。（严谨地说，这里需要做确定性验证，即要证明a此时不可能为0。您可以自己完成此处证明。）

如此便完成了Euclid辗转相除法的正确性证明。

### 分治算法的正确性检验

在递降法中允许递归函数调用自身有限次。在**算法1.2A**中，一个`gcd`只会调用一次自身，这种直接将问题转化成更简单问题的思想称为**化归**（transformation）。这一小节展示了一个多次调用自身的例子。

```c++
// 问题1.3 - 数组求和
// 输入：数组A[0:n]
// 输出：A[0]+A[1]+...+A[n-1]的和
```

> 注：`A[0:n]`用来表示大小为`n`的数组`A`。这里借用了Python的写法。
>
> 类似地，`A[l:r]`用来表示数组的一个**切片**（slice），即`A[l]`,` A[l+1]`, ...,` A[r-1]`组成的子数组。

```c++
// 算法1.3A
int f1(int* A, int n) {
    if (n == 0) { return 0; }
    if (n == 1) { return A[0]; }
    return f1(A, n/2) + f1(A + n/2, n - n/2);
}
```

您可以选取`f(A[0:n]) = n/2`，将输入数据的范围从数组映射到通常良序集上。

上述算法的正确性基于加法结合律：<u>n项的和 = 前n/2项的和 + 后(n-n/2)项的和</u>。这种将数据结构（这里是数组）分拆成几个部分，用得到的部分结果“拼出”整体结果的思想称为**分治**（divide-and-conquer）。关于**算法1.3A**的正确性检验过程，您可以仿照**算法1.2A**自己完成。

### 迭代算法的正确性检验

以上两个例子都是建立在递归上的算法。很多算法可能并不包含递归；对这些算法做有限性检验，不是要排除无穷递归，而是要排除无限循环。下面展示了一个循环的例子。

```c++
// 问题1.4 - 函数零点
// 输入：函数f(x)，区间(l,r)，误差限eps > 0
    /* 输入数据保证f(x)在数学上连续，且f(l)*f(r) < 0 */
// 输出：函数f(x)在区间(l,r)上的一个零点，绝对误差不超过eps
```

对于连续函数`f(x)`来说，由于`f(l)*f(r) < 0`，根据**零点存在定理**，它必定在区间`(l,r)`上存在零点。这个零点可以用二分的方法取得，此算法在高中数学课程中介绍过。

```c++
// 算法1.4A
double solve(function<double(double)> f, double l, double r, double eps) {
    while (r - l > eps) {             // 循环直到满足误差限
        double mid = l + (r - l) / 2; // 每次取(l,r)的中点
        if (f(l) * f(mid) <= 0) {     // 判断零点是否在(l,mid]中
            r = mid;
        } else {                      // 还是在(mid,r)中
            l = mid;
        }
    }
    return l;
}
```

分析循环问题的手段，和分析递归问题是相似的。<u>递归函数的参数，在循环问题里就变成了循环变量</u>。在处理**算法1.4A**的时候，首先找到**循环的停止条件**：`r – l < eps`。这个条件里，`eps`作为输入数据，在循环中是**不变量**，而`l`和`r`是循环中的**变量**。因此，使用递降法的时候可以将`eps`看成常量，而`l`和`r`作为“递归参数”。

定义映射`fs(l,r) = floor((r-l)/eps)`就可以将问题映射到通常良序集，后面的做法和前面几个例子基本相同，您可以自己完成正确性检验。请注意在证明结果正确性时要留意`f(mid) = 0`的情况。

这种<u>“将循环视为递归”然后用递降法处理</u>的方法，等价于将**算法1.4A**改写为以下与其等价的**算法1.4B**。

```c++
// 算法1.4B
double solve_r(function<double(double)> f, double l, double r, double eps) {
    function<double(double, double)> recursion;
    recursion = [f, eps, &recursion](double l, double r) -> double {
        if (r - l < eps) { return l; } // 递归边界
        double mid = l + (r - l) / 2;  // 每次取(l,r)的中点
        if (f(l) * f(mid) <= 0) {      // 判断零点是否在(l,mid]中
            return recursion(l, mid);
        } else {                       // 还是在(mid,r)中
            return recursion(mid, r);
        }
    };
    return recursion(l, r);
}
```

其通用做法是：<u>找到循环的停止条件，然后将条件中出现的、在循环内部被改变的变量视为递归的参数，以此将循环改写为递归</u>。当然，实际解题的时候犯不着费劲改写成递归再分析，用这个思路直接分析循环就可以了。

### 拓展：正确性证明的数学严谨性

在本节的最后，讨论一下和考研无关的内容：关于正确性“严谨证明”的一些争议。

```c++
// 问题1.5 - 角谷猜想
// 输入：正整数x
// 输出：对x反复进行操作：如果是奇数，乘3再加1；如果是偶数，除以2。直到x变为1为止。输出操作序列。

// 算法1.5A
list<int>& f1(int x) {
    static list<int> ans; ans.clear();
	ans.push_back(x);
    do {
        if (x % 2) {
            ans.push_back(x = 3*x+1);
        } else {
            ans.push_back(x = x / 2);
        }
    } while (x != 1);
    return ans;
}
```

这一算法的有限性并未得到证明。如果能找到一个合理的映射和良序关系证明它的有限性，那么也就证明了角谷猜想。然而目前还没有人完成对角谷猜想的严格证明，最接近这一成就的可能是陶哲轩。

> 学术界之外有相当多的人自称证明了角谷猜想，但似乎还未得到学术界的公认。

但有一个存在争议的问题是：未被证明或证伪的数学猜想，在对算法做正确性检验时能否被当成定理使用？一个猜想至今未被证伪，往往是建立在“小数据都不构成反例”的基础上的，比如在**算法1.5A**所使用的`int`范围之内，角谷猜想是绝对正确的。所以事实上，对于任意给定的`int x`，**算法1.5A**都是满足有限性的。

笔者对这个问题的态度是“**从实际需求出发**”。

以**算法1.5A**为例，不考虑`int`的范围限制，它的正确性取决于使用者希望用这个算法达成什么需求。如果使用这个算法的目的是“验证角谷猜想在小范围内成立”，那么无疑这个算法是正确的，因为在小范围内它的有限性是可以保证的。如果使用这个算法的目的是“找到角谷猜想的反例”，那么这个算法就不是正确的，因为仅依靠这个算法自身，无论运行多少时间，都不能证明得到的操作序列是无穷的，所以算法不能保证有限性（除非角谷猜想得到了证明）。

笔者认为，实事求是的态度在计算机学科的学习、备考和研究中都非常重要，有的时候并不需要证明您使用的算法<u>在数学上是正确的</u>，甚至它<u>在数学上就是错的</u>也没有关系，只要能达成您的目的，它就是<u>在工程上是正确的</u>。

## 复杂度分析

> 我们既要绿水青山，也要金山银山。
>
> ——Chairman Xi

**复杂度**（complexity）**分析**的技术被用于评价一个算法的效率。在考试中它出现的频率比正确性检验更高。在上文中提到过，一个算法的真实效率（运行时间、占用的硬件资源）会受到所用计算机、操作系统以及其他条件的影响，因此无法用来直接进行比较。因此，进行复杂度分析时通常不讨论绝对的时间（空间）规模，而是采用**渐进复杂度**来表示其<u>大致的增长速度</u>。

### 复杂度记号的定义

$$
\mathbf{定义（复杂度记号）}\\
\begin{align}
&假设在问题规模为n的情况下，算法在某一计算机上执行的绝对时间单元（空间单元）的数量为T(n)。\\
&1.对充分大的n，如果T(n) \le  C⋅f(n)，其中C > 0是和n无关的常数，那么记T(n) = O(f(n))。\\
&2.	对充分大的n，如果C_1⋅g(n) \le T(n) \le C_2⋅g(n)，其中C_2 \ge C_1 > 0都是和n无关的常数，那么记T(n) = Θ(g(n))。\\
&3.	对充分大的n，如果C⋅h(n) \le T(n)，其中C > 0是和n无关的常数，那么记T(n) = Ω(h(n))。\\
&用O(⋅)、Θ(⋅)和Ω(⋅)记号表示的时间（空间）随输入数据规模的增长速度称为\mathbf{渐进复杂度}，或简称\mathbf{复杂度}。
\end{align}
$$

从上述定义中可以得到，当$T(n)$关于$n$单调递增并趋于无穷大时，$f(n)$是阶不比它低的无穷大量，$h(n)$是阶不比它高的无穷大量，而$g(n)$是和它同阶的无穷大量。

当然$T(n)$并不一定单调递增趋于无穷大。一般而言，<u>复杂度记号是在问题规模充分大的前提下，从增长速度的角度对算法效率的定性评价</u>。

> 有些教材为图省事，只介绍了$O(\cdot)$一个符号，这非常容易引起理解错误或混淆。在下一小节中会展示很多错误理解的例子。
>
> 因此，即使您准备参加的考试中不要求另外两种复杂度记号，也希望您理解这些记号。
>
> 在这本笔记中，这三种复杂度记号都会使用。其中，$\Theta(\cdot)$记号包含了比$O(\cdot)$更多的信息，如果您准备参加的考试只要求$O(\cdot)$这一个记号，您可以在不引起歧义的前提下，在作答时将笔记中的$\Theta(\cdot)$用$O(\cdot)$代替。

在上面的定义中，引入了**时间单元**和**空间单元**的概念。因为渐进复杂度的记号表示中不考虑常数，所以这两个单元的大小是可以任取的。

例如，一个时间单元可以取成：

* 一秒（毫秒、微秒、纳秒、分钟、小时等绝对单位）
* 一个CPU周期
* 一条汇编语句的执行时间
* 一次原子计算（加减乘除等）
* 一次内存读取
* 一条普通（不含循环、函数调用等）语句
* 一组普通语句

例如，一个空间单元可以取成：

* 一个比特（字节、半字、字、双字等绝对单位）
* 一个结构体（固定大小）所占空间
* 一个页（见《操作系统》相关章节）
* 一个栈帧（见《操作系统》相关章节）

这些单位并不一定能直接地相互转换。比如，即使是同一台计算机，它的“一个CPU周期”对应的绝对时间也可能会发生变化（CPU过热时降频）。但是这些单位在转换时，<u>转换倍率必然存在常数的上界</u>。比如，能正常工作的内存绝不可能需要1G个CPU周期才能完成读取。

这个常数级别的差距，在复杂度分析里被纳入到了$C$、$C_1$、$C_2$中，而<u>不会影响到渐进复杂度</u>。因此，复杂度分析成功回避了硬件、软件、环境条件等“算法外因素”对算法效率的影响。

> 值得指出的是，复杂度在回避“算法外因素”影响的同时，也让算法本身的常数效率差异成为了漏网之鱼。比如，假设一个算法A对于任意的n，都需要10^64^年计算，那么这个极其巨大的常数可以全部被C吞掉，让算法A的时间复杂度仅为O(1)；然而显然算法A的效率低到不可能忍受。

### 复杂度记号的理解误区

这一小节单独开辟出来，讨论和复杂度记号（尤其是$O(\cdot)$）有关的注意点。由于复杂度记号总是作为一门学科的背景知识出现，您可能会没有意识到这是一个相当容易混淆的概念，从而陷入某些误区而不自知。

1. <u>不可交换</u>。

   已知$n^3 = O(n^4)$，$n^2 = O(n^4)$，那么，是否有$n^3=O(n^4)=n^2$呢？显然是不可能的。

   等于号“$=$”的两边通常都是可以交换的，但在复杂度记号这里并非如此。在进行复杂度的连等式计算时，始终需要记住：

   1. <u>等式左边包含的信息不少于右边</u>。

   2. <u>复杂度记号本身损失了常数的信息</u>。因此复杂度记号只能出现在等式的右侧。如果出现在左侧，那么右侧也必须是复杂度记号。

   3. 从$\Theta(\cdot)$转换成$O(\cdot)$或$\Omega(\cdot)$，会<u>损失一侧的信息</u>。因此连等式中$\Theta(\cdot)$只能出现在$O(\cdot)$或$\Omega(\cdot)$的左侧。

      > 只有一种情况除外，就是$O(1)=\Theta(1)$。

   例如，$2n^2=\Theta(n^2)=O(n^3)=O(n^4)$是正确的。

2. <u>不可比较</u>。

   已知算法A的复杂度是$O(1)$，算法B的复杂度是$O(n)$，那么，算法A的复杂度是否低于算法B？

   这是最容易误解的一处，切不能想当然认为算法A的复杂度低于算法B。这是因为，尽管已知条件是“算法B的复杂度是$O(n)$”，但已知条件并没有排除“算法B的复杂度同时也是$O(1)$”的可能。$O(1)=O(n)$，这个式子是正确的。

   > $O(1)<O(n)$则是完全错误。

3. <u>对加减法不满足分配律</u>。

   是否有$O(H_n)-O(\ln n) =O(H_n-\ln n)=O(1)$呢？

   > 记号$H_n=\sum\limits_{i=1}^n \frac1i$用来表示**调和级数的部分和**。
   >
   > 在$n\to \infty$时，$H_n-\ln n\to \gamma$，其中$\gamma$是Euler常数。这一性质在复杂度分析的领域非常重要，之后还会再次遇到。

   答案是否定的。不论是三种复杂度记号中的哪一种，都不服从对加减法的分配律。

   不过对乘除法，分配律是成立的。比如$O(f(n))\cdot O(g(n))=O(f(n)\cdot g(n))$。

4. <u>不是所有算法</u>都能用$\Theta(\cdot)$评价。

   这个问题很容易从数学角度看出来，比如说$T(n)=n\cdot(\sin \frac{n\pi}2+1)$，就不存在“与它同阶的无穷大量”。

5. $O(\cdot)$和$\Omega(\cdot)$不代表“**最坏情况**（worst case）”和“**最好情况**（best case）”。

   仍然用上面的例子$T(n)=n\cdot(\sin \frac{n\pi}2+1)$。很容易看出这个式子是$O(n)$和$\Omega(1)$。

   再看另一个例子。

   假设一个黑箱里有$n$个除颜色外完全相同的球，其中有且仅有一个红球，其他都是黑球。连续不放回地取球，直到取出红球为止。把“一次取球”看成是一个时间单元，则取球次数为$T(n)$。

   这个例子中，错误的想法就是认为上述算法的复杂度为“最坏$O(n)$”和“最好$\Omega(1)$”。

   > 这两个例子有什么不同呢？
   >
   > 在正弦的例子中，$n$是唯一的变量，并不存在和$n$无关的变量“**情况**（case）”在影响$T(n)$。
   >
   > 在取球的例子中，$n$不再是唯一的变量，在$n$被确定了的情况下，还有<u>可好可坏的情况</u>在影响$T(n)$。

   **情况**（case）表示和问题规模$n$无关的其他输入数据。在取球的例子中，正确描述算法复杂度应该是“最坏$\Theta(n)$”和“最好$\Theta(1)$”。由于通常关心的都是最坏情况的下界和最好情况的上界，所以也可以省略一些信息，表述成“最坏$\Omega(n)$”和“最好$O(1)$”。

### 复杂度的递降计算

下面几个小节，将通过一些简单的算法，介绍复杂度分析的基本方法。更多的复杂度分析将穿插在整个《数据结构》部分中。

```c++
// 问题1.6 - 判断是否为2的幂次
// 输入：正整数n
// 输出：判断n是否为2的幂次

// 算法1.6A
bool test(int n) {
    return !(n & n-1);
}
```

**算法1.6A**展示了一个经典的判断是否为`2`的幂次的方法。使用这个算法，只需要三次计算（减，按位与，取反）就可以判定`n`是否为`2`的幂次。因此可以取$T(n) = 3 = O(1)$，从而**算法1.6A**的时间复杂度为$O(1)$。

> 也可以直接将这一条“普通语句”视为一个单元，从而让$T(n)=1=O(1)$。
>
> 如果您熟悉整数的二进制存储方式，可以自行完成这一算法的正确性证明；不熟悉的话可将此问题留待《组成原理》的相关章节。

  对于不熟悉这个技巧的编程者，可能会编写出下面的算法来解决这个问题。

```c++
// 算法1.6B
bool test2(int n) {
    if (n % 2 == 1) { 
        return n == 1;
    }
    return test2(n / 2);
}
```

这个算法涉及递归，显然它的时间复杂度不再是$O(1)$。为了证明**算法1.6B**的有限性，标准的**递降法**的做法是构造$f(n) = \max(d \mid 2^d是n的因数)$来映射到通常良序集。但对这种简单的问题，也可以直接显式地计算$T(n)$，即函数体的执行次数。显式地计算出有限的$T(n)$，也就<u>在复杂度分析的同时“顺便”证明了算法的有限性</u>。

> 设$n=k\cdot2^d$，其中$k$为正奇数，$d$为自然数。则$T(n) = T(k\cdot2^d) = 1 + T(k\cdot2^d-1) = 2 + T(k\cdot2^d-2) $
>
> $ =\cdots= d + T(k) = d + 1 = O(d) = O(\log(n/k)) = O(\log n)$

另一边的$\Omega(1)$是显然的。上面这个$T(n)$的计算过程，本质上仍然是使用了递降法，将$T(\cdot)$的参数不断递降到递归边界（正奇数$k$），思路和正确性检验的递降法是一致的，它利用了$T(\cdot)$的递归式去显式地计算这个值。

> 注：因为计算机领域广泛使用二进制，所以未指定底数的对数符号“$\log$”，底数默认为`2`。而因为**换底公式**的存在，<u>在复杂度记号下无论使用什么底数都没有区别</u>。

同样地，可以显式计算出下面这个算法的$T(n)$：

```c++
// 算法1.6C
bool test3(int n) {
    int exp2 = 1;
    while (exp2 < n) {
        exp2 *= 2;
    }
    return exp2 == n;
}
```

**算法1.6C**和**算法1.6B**并不是同一算法的循环形式和递归形式，**算法1.6C**的时间复杂度是$\Theta(\log n)$，和**算法1.6B**有所不同。

另一方面，二者的空间复杂度也有所不同。在**算法1.6C**中，只引入了1个临时变量`exp2`，因此空间复杂度是$O(1)$。而在**算法1.6B**中，看似一个临时变量都没有引入，空间复杂度也应该是$O(1)$，实则不然。在**算法1.6B**中，在达到递归边界之前，每一次递归调用的函数都在等待内层递归的返回值。到达递归边界、判断完成后，这一结果被一级一级传上去，途中调用函数占据的空间才会被销毁（具体原理见《操作系统》）。

因此，<u>对于递归算法，递归所占用的空间在复杂度意义上等于最大递归深度</u>。**算法1.6B**的空间复杂度和时间复杂度同样是$O(\log n)$和$\Omega(1)$的。

> 考试时往往更加重视**时间复杂度**，因为现代计算机的内存通常足够普通的程序使用，而且《数据结构》中涉及的大多数算法，空间复杂度要么显而易见、要么能在计算时间复杂度的时候顺便算出来。
>
> 但空间效率仍然是衡量数据结构的重要指标。这个空间效率不单指空间复杂度，也包含被复杂度隐藏下去的**和数据结构相关的常数**。比方说，如果在同一计算机上，数据结构A比数据结构B的常数低10倍，那么它就能存放10倍的数据，这个优势是非常大的——即使二者的空间复杂度一致。

注：实际上，**算法1.6B**在编译之后，很有可能和下面的算法是完全等价的：

```c++
// 算法1.6B2
bool test2_l(int n) {
    while (n % 2 == 0) {
        n /= 2;
    }
    return n == 1;
}
```

也就是说，事实上的空间复杂度是$O(1)$，而不是之前分析得到的结果。这就涉及到《数据结构》学科<u>在解题时的一个必须注意的问题</u>：

<u>在《数据结构》学科分析算法复杂度时，总是不考虑编译器优化</u>。极大可能会聪明反被聪明误。

> 当然，如果您根本不知道编译器优化这回事，就不用担心这个问题了。

### 复杂度的积分计算

递归算法的复杂度分析在之后还会讨论更多技术。在比较简单的试卷上，命题者通常不会用递归算法命题，而是使用更为简单的迭代算法，命制选择或填空题。这类题目的共同点是<u>迭代的次数非常清晰</u>。比如**算法1.6C**，可以一眼就看出来迭代的次数是$\Theta(\log n)$。

这种题目通常可以用积分计算，而不需要用递降法。下面是一个没什么实际意义的例子。

```c++
// 算法1.7
int f1(int n) {
    int s = 0;
    for (int i = 1; i <= n; i++) {
        for (int j = 1; j <= i; j++) {
            for (int k = 1; k <= j; k++) {
                for (int l = 1; l <= j; l *= 2) {
                    s += k * l;
                }
            }
        }
    }
    return s;
}
```

很容易看出，要分析算法1.7的时间复杂度，只需要算循环体被执行了几次，也就是计算：
$$
T(n)=\sum_{i=1}^n\sum_{j=1}^i j\cdot(1+\lfloor \log j\rfloor)
$$
要显式地求出这个和式非常困难。幸运的是，需要求出的是复杂度而不是精确的值，常数和小项都可以在求和过程被省略掉。这给了您两个解决它的手段：

* 离散的求和问题可以<u>直接转换成连续的积分</u>问题。
* 积分也不需要真的去求，直接<u>乘上一个线性量</u>就可以。

上面的求和式可以计算如下：
$$
T(n)=\sum_{i=1}^n\sum_{j=1}^i j\cdot(1+\lfloor \log j\rfloor)=O\left(\int_0^n\int_0^xy(1+\log y)\mathrm{d}y\mathrm{d}x\right)\\
=O\left(\int_0^n\int_0^xy\log y\mathrm{d}y\mathrm{d}x\right)=O\left(\int_0^nx^2\log x\mathrm{d}x\right)=O(n^3\log n)
$$
其中，第一步是将求和符号转换成积分；消去积分符号的过程是做了两次“乘上一个线性量”的操作。

### 拓展：问题规模

在复杂度记号的定义中，**问题规模**是一个非常感性的概念。关于问题规模的定义，一直以来都存在争议。在考试中分析复杂度时，通常不需要在意这个问题。因此在本章的末尾，简要介绍一下这个问题，之后就不再赘述了。

在引出这个问题之前，先讨论一个经典的算法。

```c++
// 问题1.8 - 幂
// 输入：正整数a、b
// 输出：a的b次幂

// 算法1.8A
int power(int a, int b) {
    int prod = 1;
    for (int i = 0; i < b; ++i) {
        prod *= a;
    }
    return prod;
}
```

在上面这个例子中，您很容易看出时间复杂度是$\Theta(b)$。当`b`比较大时，这个算法的时间效率很低。这是因为，在计算$a^b$的时候，采用的递推式是$a^b = (a(a(a(a(a\dots(a\cdot a)\dots)))))$，像普通的`b`个数相乘一样简单地循环，没有利用$a^b$的在计算上的自相似性。

事实上，如果`b`是偶数，只需要先计算$a^{b/2}$，然后将其平方即可，而不需要重复计算$b/2$次乘法。从思想上，这是一种**分治**对简单**化归**的优势。通过分治将$b$快速削减，并且和上一节的数组求和问题不同，这次会产生大量的不需要重复计算的重复子问题。

借助这一思路，就得到了经典的**快速幂算法**。下面是它的递归形式。

```c++
// 算法1.8B
int power(int a, int b) {
    if (b == 1) {
        return a;
    }
    int temp = power(a, b/2);
    if (b % 2 == 1) { 
        return temp*temp*a;
    } else {
        return temp*temp;
    }
}
```

您很容易借助递降法算出，上述算法的复杂度是$\Theta(\log b)$。

现在问题来了：这个算法的**问题规模**是什么？

* 最普遍被接受，也最自然的想法是，它的问题规模是$b$。这样，**算法1.8A**和**算法1.8B**的复杂度都可以用这个问题规模表示；至于`a`的值，则被归入“情况”的范畴，并且它也不会影响到这两个算法的复杂度。
* 另一种学说认为，它的问题规模是$\log b$。这一学说的依据是：**问题规模**应当是<u>描述这一问题需要的数据规模</u>。在这个问题中，要描述问题中的`b`，在二进制计算机中需要$\log b$个比特的数据，所以问题规模是$\log b$。

这两种方法各有利弊。第一种学说的优点在于形象直观，容易理解；第二种学说的优点则在于有迹可循，定义统一。下面描述两个情景，展示这两种学说各自的优点。

* 算法的输入数据只有一个`n`，但算法要求<u>随机生成</u>大小为`n`的数组，然后计算这个数组的数据和。那么，“空间派”认为数据规模是$\log n$，得到的复杂度就是$\Theta(2^{\log n})$，这个<u>凭空出现的幂次显然会给人带来理解上的困扰</u>。相比之下，“直观派”得到的复杂度$\Theta(n)$就更加容易理解和接受。
* 在**算法1.8B**中，如果`b`的数据范围允许超出`int`限制（高精度表示，Java的BigInteger，Python中的大整数），那么`b`势必要用数组或类似的数据结构表示。这个时候，“直观派”也倾向于将“数组的大小”，也就是$\log b$作为问题规模。从这个例子可以看出，“直观派”不一定能做到让**问题规模**的定义保持统一；而“空间派”就能做到这一点。

在大多数情况下，这两种学说并无分歧。为简单起见，笔者在后文中采用“直观派”的思路。

> 注：虽然这个问题存在争议，但通常这个争议不会对解题有任何影响。

